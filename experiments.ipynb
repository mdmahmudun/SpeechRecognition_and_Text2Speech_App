{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f554642-a38b-4d60-8bf4-324ee7cd4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers.utils import logging\n",
    "from transformers import pipeline\n",
    "logging.set_verbosity_error()\n",
    "import gradio as gr\n",
    "asr = gr.Blocks()\n",
    "\n",
    "# Get the speech recognizer model\n",
    "speech_recognizer = pipeline(task = 'automatic-speech-recognition',\n",
    "                             model = 'distil-whisper/distil-small.en')\n",
    "\n",
    "def transcribe(filepath):\n",
    "    if filepath is None:\n",
    "        gr.Warning('No audio found, please retry.')\n",
    "        return ''\n",
    "    output = speech_recognizer(\n",
    "        filepath,\n",
    "        max_new_tokens = 256,\n",
    "        chunk_length_s = 30,\n",
    "        batch_size = 1   # If you have more computational capability, you can increase the batch size\n",
    "    )\n",
    "    return output['text']\n",
    "\n",
    "mic_transcribe = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=gr.Audio(sources=\"microphone\",\n",
    "                    type=\"filepath\"),\n",
    "    outputs=gr.Textbox(label=\"Transcription\",\n",
    "                       lines=3),\n",
    "    allow_flagging=\"never\")\n",
    "\n",
    "file_transcribe = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=gr.Audio(sources=\"upload\",\n",
    "                    type=\"filepath\"),\n",
    "    outputs=gr.Textbox(label=\"Transcription\",\n",
    "                       lines=3),\n",
    "    allow_flagging=\"never\",\n",
    ")\n",
    "\n",
    "with asr:\n",
    "    gr.TabbedInterface(\n",
    "        [mic_transcribe,\n",
    "         file_transcribe],\n",
    "        [\"Transcribe Microphone\",\n",
    "         \"Transcribe Audio File\"],\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Add Markdown content\n",
    "markdown_content_asr = gr.Markdown(\n",
    "    \"\"\"\n",
    "    <div style='text-align: center; font-family: \"Times New Roman\";'>\n",
    "        <h1 style='color: #FF6347;'>Automatic Speech Recognition</h1>\n",
    "        <h3 style='color: #4682B4;'>Model: distil-whisper/distil-small.en</h3>\n",
    "        <h3 style='color: #32CD32;'>Made By: Md. Mahmudun Nabi</h3>\n",
    "    </div>\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Combine the Markdown content and the demo interface\n",
    "asr_with_markdown = gr.Blocks()\n",
    "with asr_with_markdown:\n",
    "    markdown_content_asr.render()\n",
    "    asr.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b251cf4-4641-46a8-9b71-b79f8176a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the text to speech model\n",
    "narrator = pipeline(task = 'text-to-speech',\n",
    "                    model = 'kakao-enterprise/vits-ljs')\n",
    "\n",
    "import numpy as np\n",
    "from phonemizer.backend.espeak.wrapper import EspeakWrapper\n",
    "EspeakWrapper.set_library('C:\\Program Files\\eSpeak NG\\libespeak-ng.dll')\n",
    "\n",
    "def narrate_text(text):\n",
    "    # Generate the narrated audio\n",
    "    narrated_text = narrator(text)\n",
    "    audio = narrated_text['audio'][0]\n",
    "    sampling_rate = narrated_text['sampling_rate']\n",
    "    # Convert the audio to a format playable in Gradio\n",
    "    return sampling_rate, audio\n",
    "\n",
    "# Create the Gradio interface\n",
    "text_to_speech_interface = gr.Interface(\n",
    "    fn=narrate_text, \n",
    "    inputs=gr.Textbox(lines=5, placeholder=\"Enter text here...\", label = \"Input Text\"), \n",
    "    outputs = 'audio',\n",
    "    allow_flagging = 'never'\n",
    ")\n",
    "\n",
    "# Add Markdown content\n",
    "markdown_content_text2speech = gr.Markdown(\n",
    "    \"\"\"\n",
    "    <div style='text-align: center; font-family: \"Times New Roman\";'>\n",
    "        <h1 style='color: #FF6347;'>Text to Speech</h1>\n",
    "        <h3 style='color: #4682B4;'>Model: kakao-enterprise/vits-ljs</h3>\n",
    "        <h3 style='color: #32CD32;'>Made By: Md. Mahmudun Nabi</h3>\n",
    "    </div>\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Combine the Markdown content and the demo interface\n",
    "text2speech_with_markdown = gr.Blocks()\n",
    "with text2speech_with_markdown:\n",
    "    markdown_content_text2speech.render()\n",
    "    text_to_speech_interface.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f2d5bb8-69aa-4cf0-81b5-19c32b89c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = gr.Blocks()\n",
    "with app:\n",
    "    gr.TabbedInterface(\n",
    "        [asr_with_markdown,\n",
    "         text2speech_with_markdown],\n",
    "        [\"Automatic Speech Recognition\",\n",
    "         \"Text to Specch\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18477ec3-1166-4925-8d95-00c2b5228dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31cda340-9a68-43e9-9564-310d42b3b5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7869\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c72c53-da1b-49b7-9bce-e6e10f8a37ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
